{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Encoder_decoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aT6rzDJukZDTezEPoPlrT3FYDR9o8hfm",
      "authorship_tag": "ABX9TyMtpy5iKS1Ex8jt9usOXvX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patelhiren3385/NLP/blob/master/Encoder_decoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ6D5vCiKuoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4967dcd8-b01f-4732-f1cf-5ae729e8a9da"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_-8r2GQEBcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3826219-12be-486b-9741-64fb5a1d3c7a"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf2VLK-HEHKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ade86e5-f713-4541-feee-a0638a20c06d"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/YOLO/Encoder_decoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/YOLO/Encoder_decoder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsUXG_xSEVIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eac31022-90a2-4e63-9bfc-c47c307ceccc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training_eng_hindi.xml\tValidation_eng_hindi.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftXZCGTjH2XK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d30a77e6-9d87-4fa8-fc91-66f3a1136366"
      },
      "source": [
        "eng_alphabates = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_char2index = {pad_char: 0}\n",
        "\n",
        "for index,char_ in enumerate(eng_alphabates):\n",
        "  eng_char2index[char_] = index+1 \n",
        "print(eng_char2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_UzptroK_Td",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "964f88a0-9067-44cf-9cca-2a2ffb2cf6cd"
      },
      "source": [
        "hindi_alphabates = [chr(alpha) for alpha in range(2304,2432)]\n",
        "hindi_char2index = {pad_char:0}\n",
        "\n",
        "for index,char in enumerate(hindi_alphabates):\n",
        "  hindi_char2index[char] = index+1\n",
        "print(hindi_char2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yFQNp6eMZPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "def cleanEnglishVocab(line):\n",
        "  line = line.replace('-',' ').replace(',',' ').upper()\n",
        "  line = non_eng_letters.sub('',line)\n",
        "  return line.split()\n",
        "\n",
        "def cleanHindiVocab(line):\n",
        "  line = line.replace('-',' ').replace(',',' ')\n",
        "  cleaned_line = ''\n",
        "  for char in line:\n",
        "    if char in hindi_char2index or char == ' ':\n",
        "      cleaned_line += char\n",
        "  return cleaned_line.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3axobzoFGTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET \n",
        "\n",
        "class TransliterationDataset(Dataset):\n",
        "  def __init__(self,filename):\n",
        "    self.eng_words, self.hindi_words = self.readXML(filename,cleanHindiVocab)\n",
        "    self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "    random.shuffle(self.shuffle_indices)\n",
        "    self.shuffle_start_index = 0 \n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.eng_words)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.eng_words[idx],self.hindi_words[idx]\n",
        "\n",
        "  def readXML(self,filename,hindi_vocab_clean):\n",
        "    transliterationCorpus = ET.parse(filename).getroot()\n",
        "    lang1_words = []\n",
        "    lang2_words = []\n",
        "\n",
        "    for line in transliterationCorpus:\n",
        "      wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "      wordlist2 = hindi_vocab_clean(line[1].text)\n",
        "\n",
        "      if len(wordlist1) != len(wordlist2):\n",
        "        print('skip: ', line[0].text , ' - ', line[1].text)\n",
        "        continue\n",
        "      for word in wordlist1:\n",
        "        lang1_words.append(word)\n",
        "      for word in wordlist2:\n",
        "        lang2_words.append(word)\n",
        "\n",
        "    return lang1_words, lang2_words\n",
        "\n",
        "  def get_random_sample(self):\n",
        "    return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "\n",
        "  def get_batch(self,batch_size, postprocess = True):\n",
        "    eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "    hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "    self.shuffle_start_index = 0\n",
        "\n",
        "    #Reshuffle if one epoch is complete\n",
        "    if self.shuffle_start_index >= len(self.end_words):\n",
        "      random.shuffle(self.shuffle_indices)\n",
        "      self.shuffle_start_index = 0\n",
        "\n",
        "    return eng_batch, hindi_batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_KMOBlsmEug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0730447c-46c4-449d-d1c2-d7485f9820da"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training_eng_hindi.xml\tValidation_eng_hindi.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDcEhbuBF0IZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "d6d588ec-5d6e-4203-ac21-d11cdc723db9"
      },
      "source": [
        "train_data = TransliterationDataset('Training_eng_hindi.xml')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "skip:  BARHARWA JUNCTION  -  बरहरवा\n",
            "skip:  STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "skip:  SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "skip:  KING EDWARD VII  -  किंग एडवर्ड\n",
            "skip:  DIBANG VALLEY  -  दिबंगवैली\n",
            "skip:  ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "skip:  AZAMNAGAR ROAD  -  आज़मनगर\n",
            "skip:  CAPE TOWN  -  केपटाउन\n",
            "skip:  NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "skip:  SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "skip:  RAMCOIND  -  राम्को इंड\n",
            "skip:  KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "skip:  AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "skip:  JAHAN AARA  -  जहाँआरा\n",
            "skip:  NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "skip:  RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "skip:  FAKHRUN NISA  -  फखरुन्निसा\n",
            "skip:  REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "skip:  OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "skip:  OPENTV  -  ओपन टीवी\n",
            "skip:  ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "skip:  WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "skip:  VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "skip:  PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "skip:  PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "skip:  MAUNA LOA  -  मौनालोआ\n",
            "skip:  MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "skip:  STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "skip:  NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "skip:  LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "skip:  RETALIX  -  रेटालिक्स लि.\n",
            "skip:  SRISAILAM  -  श्री शैलम\n",
            "skip:  KARA-KUM  -  काराकुम\n",
            "skip:  WIND RIVER  -  विंडरिवर\n",
            "skip:  NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "skip:  ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "skip:  WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "skip:  COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "skip:  BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPjJTlPQmIfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "40c5d986-2811-4700-f02e-0f521c3a26d1"
      },
      "source": [
        "for i in range(10):\n",
        "  eng, hindi = train_data.get_random_sample()\n",
        "  print(eng , ' - ' , hindi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KULLURSANDAI  -  कुल्लुरसन्दई\n",
            "CHASE  -  चेस\n",
            "IRSHAD  -  इरशाद\n",
            "PYAR  -  प्यार\n",
            "SINDOOR  -  सिंदूर\n",
            "FORT  -  फोर्ट\n",
            "OF  -  ऑफ\n",
            "CAMPBELL  -  केम्पबेल\n",
            "RESERVOIR  -  रिज़रवायर\n",
            "PRADYOT  -  प्रद्योत\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXFggMVAmsUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordEncoding:\n",
        "  def __init__(self, eng_indexing, hindi_indexing, device = 'cpu'):\n",
        "    self.eng_indexing = eng_indexing\n",
        "    self.hindi_indexing = hindi_indexing\n",
        "    self.device = device\n",
        " \n",
        "  def encode_now(self,word):\n",
        "    if word[0] in self.eng_indexing:\n",
        "      letter2index = self.eng_indexing\n",
        "      encode = torch.zeros(len(word)+1, 1 , len(letter2index)).to(self.device)\n",
        "      for index,letter_word in enumerate(word):\n",
        "        pos = letter2index[letter_word]\n",
        "        encode[index][0][pos] = 1\n",
        "      pad_pose = letter2index[pad_char]\n",
        "      encode[index+1][0][pad_pose] = 1\n",
        "      return encode\n",
        "    else:\n",
        "      letter2index = self.hindi_indexing\n",
        "      encode = torch.zeros([len(word)+1,1], dtype=torch.long).to(self.device)\n",
        "      for index, letter_word in enumerate(word):\n",
        "        pos = letter2index[letter_word]\n",
        "        encode[index][0] = pos\n",
        "      encode[index+1][0] = letter2index[pad_char]\n",
        "      return encode\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0u0Zis-wD00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "33c841c3-e678-477e-df5f-359f0bc77bb2"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "Encode_ = WordEncoding(eng_char2index,hindi_char2index)\n",
        "Encode_.encode_now(eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEvzMrlK9sYt",
        "colab_type": "text"
      },
      "source": [
        "# Encoder Decoder with GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qv52Lkt4TYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, verbose = False):\n",
        "    super(Transliteration_EncoderDecoder,self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size,hidden_size)\n",
        "    self.decoder_rnn_cell = nn.GRU(output_size,hidden_size)\n",
        "\n",
        "    self.hidden_2_output = nn.Linear(hidden_size,output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim = 2)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "    #Encoder\n",
        "    out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "    if self.verbose:\n",
        "      print(\"Encoder Input Size: \", input.shape)\n",
        "      print(\"Encoder Hidden Size: \", hidden.shape)\n",
        "      print(\"Encoder Output Size: \", out.shape)\n",
        "\n",
        "    #Decoder\n",
        "    decoder_state = hidden \n",
        "    decoder_input = torch.zeros(1,1,self.output_size)\n",
        "    outputs = []\n",
        "\n",
        "    if self.verbose:\n",
        "      print(\"Decoder State Size: \", decoder_state.shape)\n",
        "      print(\"Decoder Input Size: \", decoder_input.shape)\n",
        "    \n",
        "    for i in range(max_output_chars):\n",
        "\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input,decoder_state)\n",
        "      if self.verbose:\n",
        "        print(\"Decoder Intermediate Output Size: \", out.shape)\n",
        "      \n",
        "      out = self.hidden_2_output(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1,-1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder Output size: ',out.shape)\n",
        "        self.verbose = False\n",
        "\n",
        "      max_idx = torch.argmax(out, 2, keepdim = True)\n",
        "      if not ground_truth is None:\n",
        "        max_idx = ground_truth[i].reshape(1,1,1)\n",
        "      one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "      one_hot.zero_()\n",
        "      one_hot.scatter_(2,max_idx,1)\n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "\n",
        "    return outputs    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQOuAUOS9wNH",
        "colab_type": "text"
      },
      "source": [
        "#Encoder Decoder using Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPULIxKl9pKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "  def __init__(self,input_size, hidden_size, output_size,verbose = False):\n",
        "    super(Transliteration_EncoderDecoder_Attention,self).__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "\n",
        "    self.encoder_rnn_cell = nn.GRU(input_size,hidden_size)\n",
        "    self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "\n",
        "    self.hidden_2_output = nn.Liner(hidden_size, output_size)\n",
        "    self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.attention = nn.Linear(self.hidden_size, 1)\n",
        "    self.output_2_hidden = nn.Linear(self.output_size, self.hidden_size)\n",
        "\n",
        "    self.verbose = verbose\n",
        "\n",
        "  def forward(self, input,max_out_chars = MAX_OUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "    # Encoder\n",
        "    encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "    encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "\n",
        "    if self.verbose:\n",
        "      print(\"Encoder Output Size: \", encoder_outputs.shape)\n",
        "\n",
        "    #Decoder\n",
        "    decoder_state = hidden\n",
        "    decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "\n",
        "    outputs = []\n",
        "    U = self.U(encoder_outputs)\n",
        "\n",
        "    if self.verbose:\n",
        "      print(\"Decoder State size: \", decoder_state.shape)\n",
        "      print(\"Decoder Intermediate Input size: \", decoder_input.shape)\n",
        "      print(\"U * Encoder Output size: \", U.shape)\n",
        "\n",
        "    for i in range(max_output_chars):\n",
        "      W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "      V = self.attention(torch.tanh(U + W))\n",
        "      attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "      \n",
        "      if self.verbose:\n",
        "          print(\"W * Decoder state Size\", W.shape)\n",
        "          print(\"V size\", V.shape)\n",
        "          print(\"Attention size\", attn_weights.shape)\n",
        "      \n",
        "      attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                            encoder_outputs.unsqueeze(0))\n",
        "      \n",
        "      embedding = self.output_2_hidden(decoder_input)\n",
        "      decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "\n",
        "      if self.verbose:\n",
        "          print('Attn LC', attn_applied.shape)\n",
        "          print('Decoder input', decoder_input.shape)\n",
        "\n",
        "      out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "      if self.verbose:\n",
        "          print('Decoder intermediate output', out.shape)\n",
        "\n",
        "      out = self.h2o(decoder_state)\n",
        "      out = self.softmax(out)\n",
        "      outputs.append(out.view(1, -1))\n",
        "\n",
        "      if self.verbose:\n",
        "        print('Decoder output', out.shape)\n",
        "        self.verbose = False\n",
        "\n",
        "      max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "      if not ground_truth is None:\n",
        "          max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "      one_hot = torch.zeros(out.shape, device=device)\n",
        "      one_hot.scatter_(2, max_idx, 1) \n",
        "\n",
        "      decoder_input = one_hot.detach()\n",
        "\n",
        "  return outputs\n",
        "\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6P2PYOJg7-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_char2index), 256 ,len(hindi_char2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv_5n0ANOOzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "087bcc46-249a-4b18-f071-553d0cbd6e0b"
      },
      "source": [
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transliteration_EncoderDecoder(\n",
            "  (encoder_rnn_cell): GRU(27, 256)\n",
            "  (decoder_rnn_cell): GRU(129, 256)\n",
            "  (hidden_2_output): Linear(in_features=256, out_features=129, bias=True)\n",
            "  (softmax): LogSoftmax(dim=2)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFz45wXtIS_U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4c665b54-0ec5-49bf-8295-ab6da6836002"
      },
      "source": [
        "def infer(net, word, char_limit, device = 'cpu'):\n",
        "    input = Encode_.encode_now(word)\n",
        "    return net(input,char_limit)\n",
        "\n",
        "\n",
        "out = infer(net,'INDIA',30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder Input Size:  torch.Size([6, 1, 27])\n",
            "Encoder Hidden Size:  torch.Size([1, 1, 256])\n",
            "Encoder Output Size:  torch.Size([6, 1, 256])\n",
            "Decoder State Size:  torch.Size([1, 1, 256])\n",
            "Decoder Input Size:  torch.Size([1, 1, 129])\n",
            "Decoder Intermediate Output Size:  torch.Size([1, 1, 256])\n",
            "Decoder Output size:  torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ri3UyJmId60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ab487ec0-ca05-43a2-aade-2024c07ac3df"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transliteration_EncoderDecoder(\n",
              "  (encoder_rnn_cell): GRU(27, 129)\n",
              "  (decoder_rnn_cell): GRU(129, 256)\n",
              "  (hidden_2_output): Linear(in_features=256, out_features=129, bias=True)\n",
              "  (softmax): LogSoftmax(dim=2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEvs1wBUJ1B3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "  net.train().to(device)\n",
        "  opt.zero_grad()\n",
        "  eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "\n",
        "  total_loss = 0 \n",
        "  for i in range(batch_size):\n",
        "    input = Encode_.encode_now(eng_batch[i])\n",
        "    ground_truth = Encode_.encode_now(hindi_batch[i])\n",
        "\n",
        "    outputs = net(input,ground_truth.shape[0],device, ground_truth= ground_truth if teacher_force else none)\n",
        "\n",
        "    for index, output in enumerate(outputs):\n",
        "      loss = criterion(output, ground_truth[index])/batch_size\n",
        "      loss.backward(retain_graph = True)\n",
        "      total_loss += loss\n",
        "\n",
        "  opt.step()\n",
        "  return total_loss/batch_size\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QOudEnSj1x-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr = 0.01, num_batches = 100 , batch_size = 10 , momentum = 0.9, display_freq = 5, device = 'cpu'):\n",
        "  net = net.to(device)\n",
        "  criterion = nn.NLLLoss(ignore_index = -1)\n",
        "  opt = optim.Adam(net.parameters(), lr = lr)\n",
        "  teacher_force_upto = num_batches//3\n",
        "\n",
        "  loss_arr = np.zeros(num_batches + 1)\n",
        "\n",
        "  for i in range(num_batches):\n",
        "    loss_arr[i+1] = (loss_arr[i]*i + train_batch(net,opt,criterion,batch_size,device,teacher_force= i<teacher_force_upto)/(i+1)\n",
        "\n",
        "    if i%display_freq == display_freq-1:\n",
        "      clear_output(wait = True)\n",
        "\n",
        "      print(\"Iteration num: \",i,\"Loss val: \", loss_arr[i])\n",
        "      plt.figure()\n",
        "      plt.plot(loss_arr[1:i], '-*')\n",
        "      plt.xlabel(\"Iteration\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.show()\n",
        "      print('\\n\\n')\n",
        "\n",
        "  torch.save(net, 'Model.pt')\n",
        "  return loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDCyG22fm--N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net,word,device = 'cpu'):\n",
        "  net = net.eval().to(device)\n",
        "  outputs = infer(net,word,30,device)\n",
        "  hindi_output = ''\n",
        "\n",
        "  for out in outputs:\n",
        "    val, indices = out.topk(1)\n",
        "    index = indices.tplist()[0][0]\n",
        "    if index == 0:\n",
        "      break\n",
        "    hindi_char = hindi_alphabates[index+1]\n",
        "    hindi_output += hindi_char\n",
        "\n",
        "  print(word + ' - ' + hindi_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG5p33Qlrb6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}